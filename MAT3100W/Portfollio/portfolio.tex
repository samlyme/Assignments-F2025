\documentclass{article}
\usepackage[margin=1in]{geometry}
\usepackage{mathtools, amsfonts, amsthm, hyperref}
\usepackage{cleveref, todonotes}
\usepackage{multicol}

\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{proposition}{Proposition}

\theoremstyle{definition}
\newtheorem{definition}{Definition}
\newtheorem{example}{Example}

\title{Proofs Portfolio\\[5pt] \large MAT 3100W: Intro to Proofs}
\author{Sam Ly}

\begin{document}
\maketitle

\section{Introduction}
In this paper, we will explore various fundamental mathematical ideas and concepts,
as well as their proofs. Proofs of high-level mathematical concepts are difficult, 
so various \textbf{proof techniques} will also be explored. We begin with the 
logical \textbf{axioms}, providing us with a way to form \textbf{statements}. Armed 
with just the our axioms, we find that new statements can be constructed. This is 
as the \textbf{direct proof}, where we manipulate logical statements to find new 
insights. Venturing further, we find \textbf{conditional statements}, and their 
accompanied proof technique, the \textbf{transformation of conditionals}.
We then explore \textbf{sets}, orderless groupings of arbitrary objects. Making 
statements about objects within sets requires the use of \textbf{quantifiers}.
Proofs of a countably infinite number of related statements are possible via a 
technique known as \textbf{induction}.
We also explore methods of defining infinities via \textbf{functions} and 
\textbf{bijections}.
We also see that our numbers are actually members of special sets. Through this 
lense, we derive the basics of \textbf{number theory} and \textbf{modular arithmetic}.
Lastly, when all hope seems lost in proving a statement, we may turn to the 
\textbf{proof by contradiction} as our last resort. This technique can only tell us 
\emph{if} a statement is true, but not \emph{why} or \emph{how}.


\section{Mathematical concepts}

In this section, we will discuss \emph{concepts} that are foundational for constructing 
and understanding mathematical proofs. Many of the concepts here build up to later 
concepts, so reading in order is recommended, but not necessarily required. Most 
concepts here will be proven later in \cref{section:proof}. These ideas form the 
basis of higher level math.

\subsection{Logic, truth tables, and DeMorgan's laws}

The foundations of mathematical reasoning is formal logic. We can form \textbf{logical statements}
that give us insights whatever we are reasoning about.

\subsubsection{Logical Statements}
\begin{definition}
    A logical statement is a statement that can either be \textbf{true} or \textbf{false}. 
    Logical statements must be unambiguous, meaning all ratioal agents with access 
    to the same information will come to the same conclusion. 
\end{definition}

\begin{example}
    ``The sun rose today.'' is a \textbf{true} logical statement.
\end{example}


\begin{proof}
    We begin by observing that the we can currently see the sun in the sky and 
    that we could not see the sun in the sky last night. If we can not see the 
    sun in the sky, it must be below the horizon. Because the sun follows a 
    continuous path, and it had been below the horizon last night, 
    it must have crossed the horizon at some point between last night and now. 
    Thus the sun must have risen today.
\end{proof}

We can then form larger statements by joining multiple statements with 
\textbf{logical connectives}. The give us the ability to express and reason about 
more complex statements.

\begin{definition}
    Logical Connectives:
    \begin{enumerate}
        \item[Disjunction:] {
            the disjunction of two statements \(P\) and \(Q\) denoted \(P \lor Q\)
            is true when either \(P\) or \(Q\) or both \(P\) and \(Q\) are true. 
        }

        \item[Conjunction:] {
            the conjunction of two statements \(P\) and \(Q\) denoted \(P \land Q\) 
            is true when both \(P\) and \(Q\) are true. 

        }

        \item[Negation:] {
            the negation of a statement \(P\) denoted \(\neg P\) is true when 
            \(P\) is false. 
        }

        \item[Implication:] {
            statement \(P\) (the \textbf{antecedent}) implies statement \(Q\) 
            (the \textbf{conclusion}) if \(Q\) is always true when \(P\) is true. 
            This is denoted \(P \rightarrow Q\). Note that if \(P\) is false, 
            the entire statement is always \(vacuously true\). 
        }
    \end{enumerate}
\end{definition}

\subsubsection{Truth Tables}

To visualize the truth of large and complex statements, we find it useful to 
draw tables. Since the truth of large statements depends purely on its component 
statements, a table can be drawn to visualize how the component statements effect 
the overall statement.

\begin{definition}
    Certain logical statements' \textbf{truth value} depends on the truth of 
    other statements. For example, ``the sun rose today \textbf{and} it rained 
    today'' requires both statements to be true in order for the overall statements 
    to be true. If the sun rose but it didn't rain, or if the sun hasn't risen 
    but it is raining, the overall statement is false. Thus, to visualize this 
    relationship, it is useful to have a table to lay out the possibilities. 
\end{definition}

\begin{example}
    \(P \rightarrow Q\).
    \[
        \begin{tabular}{|c|c|c|}
        \hline
        P & Q & $A \rightarrow B$ \\
        \hline
        T & T & T \\
        T & F & F \\
        F & T & T \\
        F & F & T \\
        \hline
        \end{tabular}
    \]
\end{example}

\subsubsection{DeMorgan's Laws}

With logical statements, we can actually find algebraic rules that allow us to 
find equivalent statements that may be more useful. One of the foundational 
algebraic rules of formal logic are known as the \textbf{DeMorgan's Laws}.

\begin{definition}
    Logical statements and their combinations have their own form of algebra.  One of the fundamental rules are DeMorgan's Laws, which state how to find the complements of conjunctions and disjunctions.
\end{definition}

\begin{theorem}
    \label{prop:de-morgans-laws}
    DeMorgan's Laws:
    \begin{enumerate}
        \item \( \neg(A \land B) = \neg A \lor \neg B\)
        \item \( \neg(A \lor B) = \neg A \land \neg B\)
    \end{enumerate}
\end{theorem}


\subsection{Sets}

\begin{definition}
    Set: An unordered collection of unique elements. 
\end{definition}

\subsubsection{Unions, intersections, complements, and set differences}

\begin{definition}
    Set operations:

    \begin{enumerate}
        \item [Union:] {
            the union of two sets \(A\), \(B\) is the set that contain elements that are 
            in \(A\), or in \(B\), or both. 
            \[A \cup B = \{x \mid x \in A \lor x \in B \}.\]
        }

        \item [Intersection:] {
            the intersection of two sets \(A\), \(B\) is the set that contains 
            elements that are in both \(A\) and \(B\) at the same time.
            \[A \cap B = \{x \mid x \in A \land x \in B\}.\]
        }

        \item[Difference:] {
            the set difference of two sets \(A\), \(B\) is the set that contains 
            all elements of \(A\) that are not in \(B\). This operation is not commutative.`'
            \[A \setminus B = \{x \mid x\in A \land x \not\in B\}.\]
        }

        \item[Complement:] {
            the complement of a set \(A\) is the set of all elements that are 
            not in \(A\). For the complements of a set to be defined, it must be a subset 
            of the unversal set \(\mathcal{U}\). In other words, it is the set difference
            between \(\mathcal{U }\) and \(A\).
            \[A^c = \mathcal{U} \setminus A.\]
        }
    \end{enumerate}
\end{definition}

\begin{theorem}
    \label{def:de-morgans-sets}
    DeMorgan's Laws for Sets:
    \begin{enumerate}
        \item \( (A \cap B)^c =  A^c \cup  B^c\)
        \item \( (A \cup B)^c =  A^c \cap  B^c\)
    \end{enumerate}

\end{theorem}

\begin{proposition}
    \label{prop:generalized-demorgan}

    For all integers \(n \ge 2\):
    \begin{enumerate}
        \item \(\left( A_1 \cup A_2 \cup ... \cup A_n \right)^c = A_1^c \cap A_2^c \cap ... \cap A_n^c \)
        \item \(\left( A_1 \cap A_2 \cap ... \cap A_n \right)^c = A_1^c \cup A_2^c \cup ... \cup A_n^c \)
    \end{enumerate}

\end{proposition}

\subsubsection{Venn diagrams}

\begin{definition}
    Venn diagrams: a visual aid for understanding sets and set operations.
    \begin{center}
        \includegraphics[width=.3\textwidth]{./images/default-sets-venn.png}
    \end{center}

    
    \begin{multicols}{2}
    \begin{enumerate}
        \item [\(A \cup B\)] {
            \begin{center}
                \includegraphics[width=.3\textwidth]{./images/AuB-venn.png}
            \end{center}
        }

        \item [\(A \cap B\)] {
            \begin{center}
                \includegraphics[width=.3\textwidth]{./images/AnU-venn.png}
            \end{center}
        }

        \item[\(A \setminus B\)] {
            \begin{center}
                \includegraphics[width=.3\textwidth]{./images/AmB-venn.png}
            \end{center}
        }

        \item[\(A^c\)] {
            \begin{center}
                \includegraphics[width=.3\textwidth]{./images/Ac-venn.png}
            \end{center}
        }
    \end{enumerate}
        
    \end{multicols}
\end{definition}

\subsection{Numbers and number systems}

\begin{definition}
    Number: values that symbolize quantities. 
\end{definition}

\begin{definition}
    Number system: way of representing numbers. Some are more sophisticated than 
    others.
\end{definition}
\subsubsection{Parity, divisibility, and modular arithmetic}

\begin{definition}
    Divisibility: a number \(n \in \mathbb{Z}\) is divisible by another number 
    \(m\) if and only if \(n = k \times m\) for some integer \(k\). 
\end{definition}

\begin{definition}
    Parity: the property of a number being even or odd. The number is even if it
    is divisible by two, and odd otherwise. 
\end{definition}

\begin{definition}
    \label{def:modular-arithmetic}
    Modular arithmetic: a number system that groups numbers into equivalence 
    classes based on their remainder when divided by a specific integer. 
    More formally, for integers \(n \), \(r \), and \(m \), we say \(n \) is 
    \textbf{congruent} to \(r \) modulo \(m \) if \((n-r)\) is divisible by \(m\).
    \[n \equiv r \pmod{m} \Leftrightarrow m \mid (n - r)\]
    For example, \(5 \equiv 11 \pmod3\) since they both have a remainder 2 when 
    divided by 3, and because \(11 - 5 = 6\) is divisible by 3.

    Standard arithmetic operations \(+, -, \text{and } \times \) are well-defined
    under modular arithmetic. However, \(\div\) is not always well defined. These 
    operations work the same way as they do in standard arithmetic.
    Notice that the parity of a number is equivalent to its divisability by 2, and 
    a number's divisibility by \(m \in \mathbb{N} > 0\) is a equivalent to it being 
    congruent to \(0\) modulo \(m\). 
\end{definition}

\begin{proposition}
    \label{prop:modular-arithmetic1}
    If \(a \equiv b \pmod m\), then \(b \equiv a \pmod m \).
\end{proposition}

\begin{proposition}
    \label{prop:modular-arithmetic2}
    If \(a \equiv a' \pmod m \) and \(b \equiv b' \pmod m\), then: 
    \begin{enumerate}
        \item \(a + b \equiv a' + b' \pmod m \)
        \item \(a - b \equiv a' - b' \pmod m \)
        \item \(a \times b \equiv a' \times b' \pmod m \)
    \end{enumerate}
\end{proposition}


\subsubsection{Rational and irrational numbers}

\begin{definition}
    Rational numbers \(\mathbb{Q}\): the set of numbers that can be expressed 
    as a ratio of two integers.
\end{definition}

\begin{definition}
    Irrational numbers: the set of numbers that can't be expressed as a ratio 
    of two integers. 
\end{definition}

\begin{proposition}
    \label{prop:sqrt2-irrational}
    \(\sqrt{2}\) is irrational. 
\end{proposition}


\subsubsection{Real numbers, absolute value, and inequalities}

\begin{definition}
    Real numbers \(\mathbb{R}\): the set of all numbers on our number line.
\end{definition}

\subsubsection{Combinatorics: combinations, permutations, and factorials.}

\begin{definition}
    Combinations \(C(n, r)\): the cardinality of the set of all subsets of a specific cardinality.
\end{definition}

\begin{definition}
    Permutations \(P(n, r)\): the cardinality of the set of all orderings of a specific length.
\end{definition}

\begin{definition}
    Factorial: the product of natural numbers before it down to zero.
    \[5! = 5 \times 4 \times 3 \times 2 \times 1 .\]
\end{definition}

\subsubsection{Countable sets}
\begin{definition}
    Countable set: a set that is either finite, or that has the same cardinality as 
    natural numbers \(\mathbb{N}\). The second case is called \textbf{countably infinite}.
\end{definition}

\begin{lemma}
    \label{lemma:cartesian-product-countable}
    Let \(A\) and \(B\) be countably infinite sets. The Cartesian product \(A \times B\)
    is also countably infinite.
\end{lemma}

\begin{proposition}
    \label{prop:Q-countable}
    \(\mathbb{Q }\) is countably infinite. 
\end{proposition}

\subsubsection{Uncountable sets}
\begin{definition}
    Uncountable set: a set that is infinite and there does not exists a bijection 
    from it to the natural numbers.
\end{definition}

\begin{proposition}
    \label{prop:R-uncountable}
    \(\mathbb{R }\) is not countably infinite.
\end{proposition}

\subsection{Relations and functions}

\subsubsection{Relations and equivalence relations}

\begin{definition}
    Relation \(R\): a set of ordered pairs that represents if a two element \(a, b \in S\) 
    are related. \(a \text{and} b\) are related if and only if \((a,b) \in R\).
\end{definition}

\begin{definition}
    Properties of Relations:

    \begin{enumerate}
        \item[Reflexive:] {
            a relation \(R\) on set \(S\) is reflexive if and only if for 
            every element \(s \in S\), \(sRs\).
        }
        \item[Symmetric:] {
            a relation \(R\) on set \(S\) is symmetric if and only if for 
            every pair of elements \(s_1, s_2 \in S\), \(s_1Rs_2\) implies \(s_2Rs_1\).
        }
        \item[Transitive:] {
            a relation \(R\) on set \(S\) is transitive if and only if for 
            every trio of elements \(s_1, s_2, s_3 \in S\), \(s_1Rs_2\) and \(s_2R_s3\) 
            implies \(s_1Rs_3\). 
        }
    \end{enumerate}
\end{definition}

\begin{definition}
    Equivalence relations: a special type of relation on a set that satisfies 
    the properties of being symmetric, reflexive, and transitive.
\end{definition}

\begin{theorem}
    Congruence under modular arithmetic is an equivalence relation. 
\end{theorem}

\subsubsection{Functions}

\begin{definition}
    Function: a mapping from a set called the domain to elements in a set called 
    the codomain. 
\end{definition}


\subsubsection{Injections (one-to-one), surjections (onto), and bijections}

\begin{definition}
    Types of mappings:

    \begin{enumerate}
        \item[Injection:] {
            a function \(f: A \rightarrow B\) is injective if and only if 
            every distinct element \(a \in A\) maps to a distinct element \(f(a) \in B\).
            In other words, there does not exist a pair of elements \(a, a' \in A\) where 
            \(a \not= a'\) such that \(f(a) = f(a')\).
        }

        \item[Surjection:] {
            a function \(f: A \rightarrow B \) is surjective if and only if 
            for every element \(b \in B \), there exists \(a \in A \) such that 
            \(f(a) = b\).
        }


        \item[Bijection:] {
            a function \(f: A \rightarrow B \) is a bijection if and only if 
            it is both injective and surjective. 
        }
    \end{enumerate}
\end{definition}


\begin{lemma}
    \label{lemma:bijection-cardinality}
    If a bijection \(f: A \rightarrow B\) exists, then \(|A| = |B|\).
\end{lemma}

\begin{lemma}
    \label{lemma:cardinality-bijection}
    If \(|A| = |B|\), then a bijection \(f: A \rightarrow B\) exists.
\end{lemma}

\begin{theorem}
    \label{theorem:bijection-bidirectional}
    A bijection \(f: A \rightarrow B\) exists if and only if \(|A| = |B|\).
\end{theorem}

\section{Proof techniques}
\label{section:proof}

\subsection{Direct Proofs}
\begin{definition}
    Direct proof: using fundamental rules of logic to prove a statement. The 
    fundamental rules of logic are taken for granted as \textbf{axioms}.
\end{definition}

\begin{example}
    \Cref{prop:modular-arithmetic1} can be proven directly from definitions.
    \begin{proof}
        Assume that \(a \equiv b \pmod m \). This means that \(m \mid (a - b)\).
        Thus, \(a - b = k m \) for some \(k \in \mathbb{Z}\).

        If we multiply both sides by \(-1\), we get \(b - a = -km\). 
        
        Thus, by definition, \(m \mid (b - a)\) and \(b \equiv a \pmod m\).
    \end{proof}

    Using the properties of modular arithmetic in  \cref{def:modular-arithmetic},
    prove \cref{prop:modular-arithmetic2}

    Given \(a \equiv a' \pmod m \) and \(b \equiv b' \pmod m \):
    \begin{enumerate}
        \item {
            \(a + b \equiv a' + b' \pmod{m}\).

            \begin{proof}
                We begin with by defining \(a \equiv a' \pmod{m}\) as \(m \mid (a - a')\).
                Similarly, \(m \mid (b - b')\).

                Following from these definitions, we write:
                \begin{equation} \label{eq:1}
                    a - a' = m \times k_1
                \end{equation}
                \begin{equation} \label{eq:2}
                    b - b' = m \times k_2
                \end{equation}

                We can add equations \cref{eq:1} and \cref{eq:2} together to get 
                \(a + b - a' - b' = m \times k_1 + m \times k_2\).

                With some factoring, we get \((a + b) - (a' + b') = m (k_1 + k_2)\).

                By definition, we find that \(m \mid (a + b) - (a' + b')\), and thus
                \(a + b \equiv a' + b' \pmod{m}\).
            \end{proof}
        }

        \item {
            \(a - b \equiv a' - b' \pmod{m}\).

            \begin{proof}
                Following from Proof 1, we can instead subtract equation \cref{eq:1}
                and \cref{eq:2} to get 
                \\ \(a - b - a' + b' = m \times k_1 - m \times k_2\).

                With some factoring, we get \((a-b) - (a'-b') = m(k_1 - k_2)\).

                By definition, we find that \(m \mid (a - b) - (a' - b')\), and thus
                \(a - b \equiv a' - b' \pmod{m}\).
            \end{proof}
        }

        \item {
            \(a \times b \equiv a' \times b' \pmod{m}\).

            \begin{proof}
                Following from equation \cref{eq:1}, we get 
                \begin{equation} \label{eq:3}
                    a = a' + m \times k_1.
                \end{equation}
                Similarly, from equation \cref{eq:2}, we  get 
                \begin{equation} \label{eq:4}
                    b = b' + m \times k_2.
                \end{equation}

                By multiplying equations \cref{eq:3} and \cref{eq:4}, we get 
                \(a \times b = (a' + m\times k_1) (b' + m\times k_2)\).

                \textit{From now on, I will omit the \(\times\) symbol.}

                By distributing, we get 
                \[ab = a'b' + a'mk_2 + b'mk_1 + m^2k_1k_2.\]
                
                We can factor out \(m\) to find 
                \[ab = a'b' + m(a'k_2 + b'k_1 + mk_1k_2).\]

                We can subtract \(a'b'\) from both sides to find 
                \[ab - a'b' = m(a'k_2 + b'k_1 + mk_1k_2).\]

                By definition, we see that \(m \mid (ab - a'b')\), and, by extension, 
                \(ab \equiv a'b' \pmod{m}\).
                    
            \end{proof}
        }
\end{enumerate}
    
\end{example}

\subsection{Transformation of conditionals}

\begin{definition}
    Transformation of conditionals: using rules of conditional logic to prove 
    conditional statements. 
\end{definition}

\emph{
    For the following proofs, I will prove similar/related statements as it 
    makes it easier to see the relationships between the transformations.
    We first perform a direct proof.
}

\begin{example}
    \Cref{lemma:cardinality-bijection} can be proven directly.

    \begin{proof}
        Suppose you have two sets \(A\) and \(B\) such that \(|A| = |B| = n\). 
        Thus, the elements of \(A\) can be enumerated by \(a_i\) for \(0 < i \le n\).
        Similarly, the elements of \(B\) can be enumerated by \(b_i\) for \(0 < i \le n\). 

        So, we can construct the function \(f: A \rightarrow B\) as \(f(a_i) = b_i\). 
        \(f\) is injective because there does not exist a pair \(a_i, a_i'\) 
        such that \(f(a_i) = f(a_i')\). \(f\) is also surjective becuase for every 
        \(b_i \in B\), there exists \(a_i \in A\) such that \(f(a_i) = b_i\). 
        Therefore, by definition, \(f\) is a bijection. 
    \end{proof}
\end{example}

\subsubsection{Contrapositive proofs}
\begin{definition}
    Contrapositive: given a statement \(P \Rightarrow Q\), the converse is \(\neg Q \Rightarrow \neg P\)
    The truth value of a statement is equivalent to its contrapositive. By proving 
    the contrapositive, you also prove the original statement.
\end{definition}
\begin{example}
    \Cref{lemma:cardinality-bijection} can also be proven using its contrapositive. 
    We find that this proof is slightly simplier. 

    \begin{proof}
        We proceed by contrapositive by saying if no bijection \(f: A \rightarrow B\)
        exists, then \(|A| \not= |B|\).

        Suppose two sets \(A\) and \(B\) such that there can not exist a bijection \(f\). 
        Thus, for any \(f: A \rightarrow B\), \(f\) is either not injective or it is 
        not surjective.

        If \(f\) is not injective, then there exists \(a, a' \in A\) such that 
        \(f(a) = f(a')\). Thus, \(|A| > |B|\). However, if \(f\) is not surjective, 
        then there exists \(b \in B\) such that there does not exist \(a \in A\) where 
        \(f(a) = b\). Thus, \(|B| > |A|\). Therefore, in either case, \(|A| \not= |B|\).
    \end{proof}
\end{example}


\subsubsection{Converse statements}
\begin{definition}
    Converse: given a statement \(P \Rightarrow Q\), the converse is \(Q \Rightarrow P\)
    The truth value of a statement's converse is equivalent to its \textbf{inverse}.
\end{definition}
\begin{example}
    \Cref{lemma:bijection-cardinality} is the converse of \cref{lemma:cardinality-bijection},
    and can be proven directly.

    \begin{proof}
        Since \(f\) is injective, distinct elements \(a_i \in A\) will always map to 
        different elements \(b \in B\). In other words, \(f(a_1) \not= f(a_2)\).
        Also, since \(f \) is surjective, for all elements \(b \in B\), there exists 
        an element \(a \in A\) such that \(f(a) = b\).
        Therefore, \(|A| = |B|\).
            
    \end{proof}
\end{example}

\subsubsection{Inverse statements}
\begin{definition}
    Inverse: given a statement \(P \Rightarrow Q\), the inverse is \(\neg P \Rightarrow \neg Q\). 
    The truth value of a statement's inverse is equivalent to its \textbf{converse}.
\end{definition}
\begin{example}
    We can prove \cref{lemma:bijection-cardinality} by proving the inverse 
    of \cref{lemma:cardinality-bijection}. We will see that this is slightly 
    simplier than the direct proof. 

    \begin{proof}
        Suppose we have two sets \(A\) and \(B\) such that \(|A| \not= |B|\). Thus, 
        we have two cases: 
        \begin{enumerate}
            \item[\(|A| > |B|\):] {
                Since there are more elements \(a \in A\) than there are \(b \in B\), 
                there must be a pair of elements \(a, a' \in A\) such that \(f(a) = f(a')\). 

                Thus, \(f\) is not injective.
            }
            \item[\(|A| < |B|\):] {
                Since there are more elements \(b \in B\) than there are \(a \in A\), 
                there must exist an element \(b \in B\) such that \(f(a) \not= b\) 
                for all \(a \in A\).

                Thus, \(f\) is not surjective.
            }
        \end{enumerate}

        Therefore, \(f\) is not a bijection.
    \end{proof}
\end{example}

\subsubsection{Bidirectional ("if and only if" proofs)}
\begin{definition}
    Bidirectional proof: A bidirectional proof involves proving both a conditional
    statement and its converse to conclude that the \textbf{antecedent} and the 
    \textbf{consequent} are logically equivalent.
\end{definition}

\begin{example}
    \Cref{theorem:bijection-bidirectional} can be proven bidirectionally by proving 
    \cref{lemma:bijection-cardinality} and \cref{lemma:cardinality-bijection}.

    \begin{proof}
        We have proven both \cref{lemma:cardinality-bijection} and \cref{lemma:bijection-cardinality} above.
        Thus, \cref{theorem:bijection-bidirectional} must be true.
    \end{proof}
\end{example}

\subsection{Quantifiers}

\begin{definition}
    Quantifier: a logical expression that denotes whether a statement is true 
    for all cases or for specific cases. 
\end{definition}

\subsubsection{Universal quantifiers}
\begin{definition}
    For a statement with a universal quantifier to be true on set \(S\), the 
    statement must be true for every single \(s \in S\). Universal statements 
    can be disproven by one counterexample. 
\end{definition}

\begin{example}
    A function \(f: D \rightarrow C\) is well defined on a domain \(D\) and codomain \(C\) 
    if \(f(d) \in C\) for all \(d \in D\). Let \(f(x) = \sqrt{x}\). Is \(f: \mathbb{R} \rightarrow \mathbb{R}\) well defined? 
    
    \begin{proof}
    We find 
    that for \(x < 0\), \(f(x) \not\in \mathbb{R}\). We have not just found one 
    counterexample, we have found an uncountably infinite number of counterexamples.
    
    So, \(f\) is not well defined.
    \end{proof}
\end{example}

\subsubsection{Existential quantifiers}
\begin{definition}
    For a statement with an existential quantifier to be true on set \(S\), 
    the statement must be true for at least one \(s \in S\). Existential statements 
    can be proven by one example. 
\end{definition}

\begin{example}
    There exists a real number \(r \in \mathbb{R}\), where \(\sqrt{r} \in \mathbb{Q}\). 

    \begin{proof}
        Let \(r=4\). \(\sqrt{4} = 2 = \frac{2}{1}\). Thus, \(\sqrt{2} \in \mathbb{Q}\).
        So, there exists a real number \(r \in \mathbb{R}\), where \(\sqrt{r} \in \mathbb{Q}\). 
    \end{proof}
\end{example}

\subsubsection{Multiply quantified statements}
\begin{definition}
    Multiply quantified statement: statements that include more than one 
    quantifier. Typically, they go ``for all \(x\), there exists \(y\), such that \(z\).''
    They can be reasoned about by using an ``adversarial'' game, where player 1
    picks an \(x\) that makes it hard for player 2 to pick a \(y\) to satisfies \(z\). 
    If player 1 can pick an \(x\) such that player 2 can't pick a valid \(y\) to 
    satisfy \(z\), player 1 `wins' and the statement is false.

    In another case, the statement can go ``there exists \(x\), for all \(y\), such that \(z\). ''
    In this case, player 1 just needs to pick one value \(x\), such that for 
    all values player 2 picks for \(y\), it satisfies \(z\). This makes the 
    statement true.
\end{definition}

\begin{example}
    For all pairs of real numbers \(x, y \in \mathbb{R}\) with \(x < y\), there 
    exists a rational number \(r \in \mathbb{Q}\) such that \(x<r<y\).

    \begin{proof}
        We first define a useful interpretation of constructing rational 
        numbers by dividing two integers \(r = n/d\). We are essentially taking 
        \(n\) steps of length \(1/d\).

        Thus, if we have a sufficiently small step size, there must be an 
        integer number of steps for us to land on the range \(x < r < y\). 

        We see that if we have a step size smaller than \(y - x\), we must 
        always land within the range \(x < r < y\). 
        
        We can see this by imagining a worst case scenario where \(\frac{n-1}{d} = x\). 
        Thus, because \(1/d < y - x\), 
        \begin{align*}
            x < \frac{n-1}{d} + \frac{1}{d} &< y\\
            x < \frac{n}{d} &< y
        \end{align*}

        Similarly, we can see the other worst case scenario where \(\frac{n+1}{d} = y\). 
        Thus, because \(1/d < y - x\), 
        \begin{align*}
            x < \frac{n+1}{d} - \frac{1}{d} &< y\\
            x < \frac{n}{d} &< y
        \end{align*}

        In order to achieve a step size smaller than \(y - x\), we must 
        satisfy the condition \(1/d < y - x\). In other words, \(d > \frac{1}{y-x}\).
        Furthermore, increasing \(d\) will only decrease the step size. 

        Thus, for all pairs of real numbers \(x, y \in \mathbb{R}\) with \(x < y\), 
        we can find \(d \in \mathbb{Z}\) with \(d > \frac{1}{y-x}\). Then, there 
        must exist an integer \(n\) where \(x < n/d < y\). 
    \end{proof}

\end{example}

\subsection{Existence and uniqueness proofs}
\begin{definition}
    Existence and uniqueness proof: a proof that results in us being sure that 
    an element exists with a given property, and that it is the only element that 
    exhibits such property. 
    In many ways, existence and uniqueness proofs are equivalent to constructing 
    a bijection. 
\end{definition}

\begin{example}
    \Cref{lemma:cartesian-product-countable} can be proven using an existence and 
    uniqueness proof. 

    \begin{proof}
        Suppose sets \(A\) and \(B\) are countably infinite. By definition, 
        there exists bijections \(f_A: \mathbb{N} \rightarrow A\) and 
        \(f_B: \mathbb{N } \rightarrow B\). Thus, there must exist a bijection 
        \(f_{A \times B } : \mathbb{N}^2 \rightarrow A \times B \).

        Now, if we can prove a bijection \(f_{\mathbb{N}^2} \colon \mathbb{N} \rightarrow \mathbb{N}^2\),
        we also prove there exists a bijection \(f: \mathbb{N} \rightarrow A \times B\) because 
        of the transitivity of bijections. 

        We proceed by arranging $\mathbb{N}\times\mathbb{N}$ in a grid with rows 
        indexed by $i$ and columns indexed by $j$:
        \[
        \begin{array}{c|cccc}
        & j=1 & j=2 & j=3 & j=4 \\
        \hline
        i=1 & (1,1) & (1,2) & (1,3) & (1,4)\\
        i=2 & (2,1) & (2,2) & (2,3) & (2,4)\\
        i=3 & (3,1) & (3,2) & (3,3) & (3,4)\\
        i=4 & (4,1) & (4,2) & (4,3) & (4,4)
        \end{array}
        \]        

        \[
(1,1);\quad (1,2),(2,1);\quad (1,3),(2,2),(3,1);\quad (1,4),(2,3),(3,2),(4,1);\ \ldots
        \]

        This traversal enumerates all pairs \((i, j)\), and thus proves that 
        there exists a bijection \(f: \mathbb{N } \rightarrow \mathbb{N }^2\).
        In other words, \textbf{for any pair \((i, j)\) there exists a unique \(n \in \mathbb{N}\)
        such that the \(n^{th}\) element in this traversal is the pair}.
        Therefore, for any two countably infinite sets \(A\) and \(B\), their 
        Cartesian product is also countably infinite.
    \end{proof}
\end{example}

\begin{example}
    \Cref{prop:Q-countable} is a natural extension of \cref{lemma:cartesian-product-countable}.

    \begin{proof}
        Since rational numbers in \(\mathbb{Q}\) are constructed as the ratio of 
        two natural numbers \(a, b \in \mathbb{N}\), we can think of \(\mathbb{Q}\) 
        as the cartesian product of \(\mathbb{N}\) and itself. We notice that certain 
        pairs are equivalent. For example, \(2/4 = 1/2 \in \mathbb{Q}\), however 
        they form distinct pairs in \(\mathbb{N}^2\). Thus, in our diagonal traversal, 
        we simple skip the redundant elements. In other words \(\mathbb{Q} \subset \mathbb{N}^2\).
        Therefore, \(\mathbb{Q}\) is countably infinite.
    \end{proof}
\end{example}

\subsection{Proof by Induction}

\begin{definition}
    Proof by Induction: proof technique used to prove a statement is true for  
    a countably infinite set of discrete elements. 

    When doing proofs by induction, it is useful to enumerate the cases as 
    \(n \in \mathbb{N}\). This proof begins with a \textbf{base case} (or in some 
    scenarios \textbf{base cases}) proving that the 
    proposition is true for some ``small'' cases. Typically this means proving 
    the proposition is true for \(n = 0, 1, 2\). It is also helpful to ``play''
    to gain intuition about our problem before proceding to the inductive step. 

    We then form an \textbf{inductive hypothesis} that assumes our proposition is true for 
    cases \(n \le k\). Our \textbf{inductive step} is to prove that this assumption 
    necessarily means that the \(n = k+1\) case must be true. 

    Thus, the cases \(n\) up to \(k\) implies case \(n = k + 1\). So, starting at 
    our base case, we know that \(n = 0\) is true. Then we know that \(n = 1\) is true. 
    Since, cases \(n=0\) and \(n=1\) are true, case \(n=2\) is true. Then since 
    cases \(0 \le n \le 2\) are true, case \(n = 3\) is true, and so on.

    Now, it may seem that this proof is circular at first, since we are making a 
    massive assumption in the form of our inductive hypothesis. However, our 
    assumption is not the same as our conclusion. Our inductive hypothesis is 
    used to prove that for any case \(n = k\), its successor must be true. 
\end{definition}

\begin{example}
    \Cref{prop:generalized-demorgan} can be proven with induction.

    For the first case, we have
    \[\left( A_1 \cup A_2 \cup ... \cup A_n \right)^c = A_1^c \cap A_2^c \cap ... \cap A_n^c.\]
    \begin{proof}
        First, we define some useful notation for a union and intersection
        for a large series of sets \(A_1, A_2, ..., A_3\):
        \[ \bigcup_{i=1}^{n} A_i = A_1 \cup A_2 \cup ... \cup A_n\]
        \[ \bigcap_{i=1}^{n} A_i = A_1 \cap A_2 \cap ... \cap A_n.\]

        First, we use \cref{def:de-morgans-sets} (DeMorgan's Law for Sets)
        as the base case \(n=2\),
        \(\left( A_1 \cup A_2 \right)^c = A_1^c \cap A_2^c.\)

        Then, as our inductive hypothesis, we assume that 
        \[ \left( \bigcup_{i=1}^{n} A_i \right)^c = \bigcap_{i=1}^{n} A_i^c, \text{ for } n \le k.\]

        Then, we see that for \(n+1\), 
        \begin{align*}
            \left( \bigcup_{i=1}^{n+1} A_i \right)^c &= \left( \bigcup_{i=1}^{n} A_i \cup A_{n+1} \right)^c \\
            \left( \bigcup_{i=1}^{n+1} A_i \right)^c &= \left( \bigcup_{i=1}^{n} A_i \right)^c \cap A_{n+1}^c .\\
        \end{align*}

        We can use our inductive hypothesis to substitute 
        \(\left( \bigcup_{i=1}^{n} A_i \right)^c = \bigcap_{i=1}^{n} A_i^c\)
        to get,
        \begin{align*}
            \left( \bigcup_{i=1}^{n+1} A_i \right)^c &= \bigcap_{i=1}^{n} A_i^c \cap A_{n+1}^c .\\
            &= A_1^c \cap A_2^c \cap ... \cap A_n^c \cap A_{n+1}^c .\\
        \end{align*}

        Therefore, 
        \[\left( A_1 \cup A_2 \cup ... \cup A_n \right)^c = A_1^c \cap A_2^c \cap ... \cap A_n^c \]
        for any integer \(n \ge 2\).
    \end{proof}

    Similarly, for the second case, we have 
    \[\left( A_1 \cap A_2 \cap ... \cap A_n \right)^c = A_1^c \cup A_2^c \cup ... \cup A_n^c.\]
    \begin{proof}
        First, we use \cref{def:de-morgans-sets} (DeMorgan's Law for Sets)
        as the base case \(n=2\),
        \(\left( A_1 \cap A_2 \right)^c = A_1^c \cup A_2^c.\)

        Then, as our inductive hypothesis, we assume that 
        \[ \left( \bigcap_{i=1}^{n} A_i \right)^c = \bigcup_{i=1}^{n} A_i^c, \text{ for } n \le k.\]

        Then, we see that for \(n+1\), 
        \begin{align*}
            \left( \bigcap_{i=1}^{n+1} A_i \right)^c &= \left( \bigcap_{i=1}^{n} A_i \cap A_{n+1} \right)^c \\
            \left( \bigcap_{i=1}^{n+1} A_i \right)^c &= \left( \bigcap_{i=1}^{n} A_i \right)^c \cup A_{n+1}^c .\\
        \end{align*}

        We can use our inductive hypothesis to substitute 
        \(\left( \bigcap_{i=1}^{n} A_i \right)^c = \bigcup_{i=1}^{n} A_i^c\)
        to get,
        \begin{align*}
            \left( \bigcap_{i=1}^{n+1} A_i \right)^c &= \bigcup_{i=1}^{n} A_i^c \cup A_{n+1}^c .\\
            &= A_1^c \cup A_2^c \cup ... \cup A_n^c \cup A_{n+1}^c .\\
        \end{align*}

        Therefore, 
        \[\left( A_1 \cap A_2 \cap ... \cap A_n \right)^c = A_1^c \cup A_2^c \cup ... \cup A_n^c \]
        for any integer \(n \ge 2\).
    \end{proof}
\end{example}

\begin{example}
        Let \(F_n\) be the \(n\)-th Fibonacci number, where \(F_0 = F_1 = 1\)
        and \(F_n = F_{n-1} + F_{n-2}\). Prove that \(F_n \le 1.9^n\) for all
        \(n \ge 1\).

    \begin{proof}
        We proceed by induction, starting with the base cases, where \(n=1,2\):
        \[n = 1, F_1 = 1 \le 1.9^1 = 1.9\]
        \[n = 2, F_2 = 2 \le 1.9^2 = 3.61.\]

        We assume as an inductive hypothesis that \(F_n \le 1.9^n\) for \(1 \le n \le k\).

        Using our inductive hypothesis, we see that \(F_k \le 1.9^k\)
        and \(F_{k-1} \le 1.9^{k-1}\).
        % \[F_{k+1} \le 1.9^{k+1}\]
        % \[F_k + F_{k-1} \le 1.9^{k+1}.\]

        So, \(F_k + F_{k-1} \le 1.9^k + 1.9^{k-1}\).

        By refactoring \(1.9^k + 1.9^{k-1}\), we get:
        \[1.9^k + 1.9^{k-1} = 1.9(1.9^{k-1}) + 1.9^{k-1} = 2.9(1.9^{k-1}).\]

        Also, \(1.9^{k+1}\) can be rewritten as \(1.9^2 (1.9^{k-1}) = 3.61(1.9^{k-1})\).

        Finally, we see
        \[F_{k+1} = F_k + F_{k-1} \le 2.9(1.9^{k-1}) \le 3.61(1.9^{k-1}) = 1.9^{k+1}\]
        \[F_{k+1} \le 1.9^{k+1}.\]

        Thus, we conclude that by the principle of mathematical induction, 
        \(F_n \le 1.9^n\) for all \(n \ge 1\).
    \end{proof}
\end{example}

\begin{example}
    Look up the Tower of Hanoi puzzle. Prove that given a stack of 
    disks, you can solve the puzzle in moves.

    \begin{proof}
        We begin by defining the Tower of Hanoi problem. 
        
        In this problem, we begin 
        with a stack of \(n\) disks. The disks are ordered from largest at the bottom 
        to smallest at the top. We are also given 3 `spots' to place our disks under 
        one condition: that we never place a larger disk on top of a smaller disk. 

        Following these rules, what is the minimum number of moves required to move
        the entire pile to a new `spot'?
        
        We define the function \(f: \mathbb{N} \rightarrow \mathbb{N}\) such that it 
        maps the starting stack height \(n\) to the minimum number of moves required 
        to move the entire pile \(f(n)\).

        Before immediately proving that \(f(n) = 2^n - 1\), it is more intuitive to 
        first define \(f\) as a recurrence relation, then prove that the recurrence
        relation is equal to \(2^n -1\).

        We notice that moving the entire pile  of \(n\) disks essentially requires 3 `phases':
        \begin{enumerate}
            \item Moving the top \(n-1\) disks onto a single pile.
            \item Moving the \(n\)th disk to another vacant spot.
            \item Moving the top \(n-1\) disks onto the new spot.
        \end{enumerate}

        Thus, we know that \(f(n) = f(n-1) + 1 + f(n-1) = 1 + 2f(n-1)\), where \(f(1) = 1\).
        We can then prove \(f(n) = 2^n -1\) using induction. 

        We begin with our base cases:
        \begin{center}
            \begin{tabular}{c c}
                \(n\)   & \(f(n)\) \\
                \hline \\
                1       & \(1 = 2^1 - 1\)\\
                2       & \(3 = 2^2 - 1\) \\
                3       & \(7 = 2^3 - 1\) \\
            \end{tabular}
        \end{center}

        Now, we assume that \(f(k) = 2^k -1 \) for all \(1 \le k \le n\).
        
        We see that
        \[f(k+1) = 1 + 2f(k)\]
        \[f(k+1) = 1 + 2(2^k - 1)\]
        \[f(k+1) = 2^{k+1} - 1.\]

        Thus, \(f(n) = 2^n - 1\).
    \end{proof}
\end{example}

\subsection{Proof by Contradiction}

\begin{definition}
    Proof by contradiction: proof technique that assumes the opposite of 
    our proposition, then showing that this leads to an absurd conclusion,
    ie. a contradiction. Used as a ``last resort'' proof technique. 

    This proof works because all statements in our mathematical universe can 
    either be true or false. Thus, by assuming the opposite of our proposition, 
    and showing that the opposite of our proposition \textbf{can not} be true, 
    our original proposition then \textbf{must} be true. We show that the 
    opposite of our proposition can't be true through finding a contradiction.

    This proof technique is used as a last resort since it doesn't necessarily
    tell you much abou why/how our proposition is true, just that it must be true. 
\end{definition}

\begin{example}
    \Cref{prop:sqrt2-irrational} can be proven by contradiction.

    We proceed by contradiction by assuing that \(\sqrt{2} \in \mathbb{Q}\).
    So, we can write
    \[\sqrt{2} = \frac{a }{b }\]
    for \(a, b \in \mathbb{N}\), and such that \(\frac{a}{b}\) is in lowest form. 

    Then, with algebraic manipulation, we see 
    \begin{align*}
        2 = \frac{a^2}{b^2}.
    \end{align*}

    Thus, we get \(a^2 = 2b^2\) and \(b^2 = a^2/2\). So, \(a^2\) is even, and 
    by extension, \(a\) is even. Since \(a\) is even, we write \(a = 2m\) for 
    \(m \in \mathbb{Z}\). Thus,
    \begin{align*}
        b^2 &= \frac{(2m)^2}{2}, \\
        b^2 &= \frac{4m^2}{2}, \\
        b^2 &= 2m^2,
    \end{align*}
    showing that \(b^2\) must also be even.

    This is a contradiction because we assumed that \(a/b\) was in lowest
    terms, however, we have just found a way to factor out a common 2. This 
    contradiction shows that our original proposition was be false. So, 
    \(\sqrt{2}\) must be irrational.
\end{example}

\begin{example}
    \Cref{prop:R-uncountable} can be proven by contradiction. This is the famous 
    Cantor's diagonalization argument. 

    First we assume that \(\mathbb{R}\) is countably infinite. In other words, 
    \(|\mathbb{R}| = |\mathbb{N}|\), and that there exists a bijection between 
    \(\mathbb{R}\) and \(\mathbb{N}\).

    Thus, we can list out all the real numbers \(r_i \in \mathbb{R}\) for \(i \in \mathbb{N}\)
    in a table as follows where the rows are distinct real numbers \(r_i\) and the 
    columns are their decimal places:
    \[
\begin{array}{r|ccccccc}
      & 10^{-1} & 10^{-2} & 10^{-3} & 10^{-4} & 10^{-5} & \cdots \\ \hline
r_{1} & \mathbf{a_{11}} & a_{12} & a_{13} & a_{14} & a_{15} & \cdots & a_{1n}\\
r_{2} & a_{21} & \mathbf{a_{22}} & a_{23} & a_{24} & a_{25} & \cdots & a_{2n}\\
r_{3} & a_{31} & a_{32} & \mathbf{a_{33}} & a_{34} & a_{35} & \cdots & a_{3n}\\
r_{4} & a_{41} & a_{42} & a_{43} & \mathbf{a_{44}} & a_{45} & \cdots & a_{4n}\\
r_{5} & a_{51} & a_{52} & a_{53} & a_{54} & \mathbf{a_{55}} & \cdots & a_{5n}\\
\vdots     & \vdots & \vdots & \vdots & \vdots & \vdots & \ddots \\
r_{n} & a_{n1} & a_{n2} & a_{n3} & a_{n4} & a_{n5} & \cdots & \mathbf{a_{nn}}\\
\vdots     & \vdots & \vdots & \vdots & \vdots & \vdots & \ddots
\end{array}
\]

    Then, we see the bolded diagonal. With this diagonal, for each \(a_{jj}\) for 
    \(j \in \mathbb{N}\), we can construct an \textbf{entirely new} real number 
    just be changing \(a_{jj}\). In the original arument, Cantor states to add 1 
    if \(a_{jj} < 9\) and to subtract 1 if \(a_{jj} = 9\). However a more general 
    way of saying this is to just pick a new integer \(0 \le a_{jj}' \le 9\)
    that is not equal to \(a_{jj}\).

    So, we have now constructed a new real number, contradicting our assumption. 
    Thus, we see that \(\mathbb{R}\) must not be countably infinite.
\end{example}

\section{Final project}

\section{Conclusion and reflection}

Throughout this semester, I've found myself struggling with many concepts and 
problems. However, the problem that I struggled with most and that was the most 
memoriable is Choice Exercise 10 from HW08. It was memoriable for a very precise 
reason: that it truly exposed my weaknesses in problem solving. In class, we 
discussed the concept of ``over abstracting'' problems before we are truly ready 
to, and that is exactly what happend during my attempt at this problem.

I know I shouldn't have spent so much time on this one problem, but I spent 
literal hours engrossed in this problem trying to come up with ``clean'' algorithm 
to calculate the number of transitive and anti-transitive relations that could run 
with good asymptotic performance. Now, I love a a good puzzle, so I avoided looking 
at hints for a while. Eventually I came to my senses and realized that this wasn't 
even the problem that was assigned. I've been trained to always try to find the 
``best'' solution in terms of algorithmic performance, that I just default to throwing 
out the brute force solution, and that was exactly what I need! When I eventually 
looked up the solution, I realized that there isn't actually a good closed formula 
for this yet! In retrospect, it's obvious that the brute force solution should be the very first 
solution I test and come up with, and there was no reason for me to try to optimize 
the algorithmic performance before I even had a working solution. Although I've 
heard this before, and I myself believe it, this experience with the problem
really goes to show that premature optimization is root of all evil. 

Zooming out slightly, I find that this course really felt like a primer for a lot 
of math topics that I am curious about. It's made math topics with scary names like 
``Category Theory'' slightly less intimidating, and has really made me more curious 
to learn more about them. Specifically, I would like to explore the intersection 
between higher level math and Computer Science in areas like Type theory and 
compiler optimization. This goes hand in hand with my mathematical imagination. I 
feel as though this course really opened my eyes to higher level math. 


\pagebreak
\appendix
\begin{center}
    \LARGE Appendix
\end{center}
\noindent (The first section, ``Course objectives and student learning outcomes'' is just here for your reference.)
\section{Course objectives and student learning outcomes}

\begin{enumerate}
    \item Students will learn to identify the logical structure of mathematical statements and apply appropriate strategies to prove those statements.
    \item Students learn methods of proof including direct and indirect proofs (contrapositive, contradiction) and induction.
    \item Students learn the basic structures of mathematics, including sets, functions, equivalence relations, and the basics of counting formulas.
    \item Students will be able to prove multiply quantified statements.
    \item Students will be exposed to well-known proofs, like the irrationality of $\sqrt{2}$ and the uncountability of the reals.
\end{enumerate}

\subsection{Expanded course description}
\begin{itemize}
    \item Propositional logic, truth tables, DeMorgan's Laws
    \item Sets, set operations, Venn diagrams, indexed collections of sets
    \item Conventions of writing proofs
    \item Proofs
    \begin{itemize}
        \item Direct proofs
        \item Contrapositive proofs
        \item Proof by cases
        \item Proof by contradiction
        \item Existence and Uniqueness proofs
        \item Proof by Induction
    \end{itemize}
    \item Quantifiers
    \begin{itemize}
        \item Proving universally and existentially quantified statements
        \item Disproving universally and existentially quantified statements
        \item Proving and disproving multiply quantified statements
    \end{itemize}
    \item Number systems and basic mathematical concepts
    \begin{itemize}
        \item The natural numbers and the integers, divisibility, and modular arithmetic
        \item Counting: combinations and permutations, factorials
        \item Rational numbers, the irrationality of $\sqrt{2}$
        \item Real numbers, absolute value, and inequalities
    \end{itemize}
    \item Relations and functions
    \begin{itemize}
        \item Relations, equivalence relations
        \item Functions
        \item Injections, surjections, bijections
    \end{itemize}
    \item Cardinality
    \begin{itemize}
        \item Countable and uncountable sets
        \item Countability of the rational numbers, $\mathbb{Q}$
        \item Uncountability of the real numbers, $\mathbb{R}$
    \end{itemize}
\end{itemize}
\end{document}
